# 

# 7.1 DIAGONALIZATION OF SYMMETRIC MATRICES

A **symmetric matrix** is a matrix $$A$$ such that $$A^T = A$$. Such a matrix is necessarily square.
Its main diagonal entries are arbitrary, but its other entries occur in pairsâ€”on opposite
sides of the main diagonal.

## Theorem 1

If $$A$$ is symmetric, then any two eigenvectors from different eigenspaces are orthogonal.

### Proof

Let $$\textbf{v}_1$$ and $$\textbf{v}_2$$ be eigenvectors that correspond to distinct eigenvalues, say, $$\lambda_1$$ and $$\lambda_2$$. To show that $$\textbf{v}_1 \cdot \textbf{v}_2 =0$$, compute

$$
\begin{align*}
\lambda_1 \textbf{v}_1 \cdot \textbf{v}_2 &= (\lambda_1 \textbf{v}_1)^T \textbf{v}_2 = (A\textbf{v}_1)^T\textbf{v}_2 & \text{ Since } \textbf{v}_1 \text{ is an eigenvector} \\
&= (\textbf{v}_1^T A^T)\textbf{v}_2 = \textbf{v}_1^T (A \textbf{v}_2) & \text{ Since } A^T = A \\
&= \textbf{v}_1^T (\lambda_2 \textbf{v}_2) & \text{ Since } \textbf{v}_2 \text{ is an eigenvector} \\
&= \lambda_2 \textbf{v}_1^T \textbf{v}_2 = \lambda_2 \textbf{v}_1 \cdot \textbf{v}_2
\end{align*}
$$

Hence $$(\lambda_1 = \lambda_2) \textbf{v}_1 \cdot \textbf{v}_2 = 0$$. But $$\lambda_1 - \lambda_2 \ne 0$$, so $$\textbf{v}_1 \cdot \textbf{v}_2 = 0. \blacksquare $$ 

An $$n \times n$$ matrix $$A$$ is said to be **orthogonally diagonalizable** if there are an **orthogonal matrix** $$P$$ (with $$P^{-1}= P^T$$ ) and a diagonal matrix $$D$$ such that

$$
A = PDP^T = PDP^-{-1} \tag{1}
$$

Such a diagonalization requires $$n$$ linearly independent and orthonormal eigenvectors. When is this possible? If $$A$$ is orthogonally diagonalizable as in (1), then

$$
A^T = (PDP^T)^T = P^{TT}D^{T}P^{T} = PDP^T = A
$$

Thus $$A$$ is symmetric! Theorem 2 below shows that, conversely, **every symmetric matrix
is orthogonally diagonalizable**. The proof is much harder and is omitted; the main idea
for a proof will be given after Theorem 3.

## Theorem 2

An $$n \times n$$ matrix $$A$$ is orthogonally diagonalizable if and only if $$A$$ is a symmetric matrix.

